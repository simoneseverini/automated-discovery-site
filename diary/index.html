<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>

    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      chtml: {
        scale: 1,                      
        minScale: .5,                  
        matchFontHeight: true         
      }
    };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <style>
        /* --- VARIABLES --- */
        :root {
            --bg: #f4f4f4;
            --card-bg: #ffffff;
            --text: #111;
            --meta: #666;
            --accent: #0056b3;
            --badge-bg: #eef3f8;
            --border: #eee;
            --code-bg: #f8f8f8;
        }

        /* --- GLOBAL LAYOUT --- */
        * {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            padding: 0;
            background-color: var(--bg);
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            color: var(--text);
            line-height: 1.6;
            /* Prevent horizontal scroll on the body caused by overflowing elements */
            overflow-x: hidden;
        }

        header {
            padding: 50px 20px 30px 20px;
            text-align: center;
        }

        h1 {
            margin: 0;
            font-size: 2.0rem;
            letter-spacing: -0.01em;
            font-weight: 700;
            font-family: "Courier New", Courier, monospace;
        }

        header p {
            margin: 10px 0 0 0;
            color: var(--meta);
            font-size: 0.95rem;
        }

        h3, h4 {
            margin-top: 1.5em;
            margin-bottom: 0.8em;
            color: #333;
        }

        h3 {
            font-size: 1.15rem;
        }

        h4 {
            font-size: 1rem;
            color: #444;
        }

        /* --- CONTAINER --- */
        .diary-container {
            max-width: 850px;
            margin: 0 auto;
            padding: 0 20px 100px 20px;
            width: 100%;
        }

        /* --- ENTRY CARD STYLE --- */
        .entry {
            background: var(--card-bg);
            padding: 40px;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.04);
            margin-bottom: 30px;
            border: 1px solid transparent;
            transition: border-color 0.2s ease;
            
            /* FIX 1: Use overflow-wrap (standard) instead of word-break (aggressive).
               This breaks long words if necessary but respects HTML tags (like math). */
            overflow-wrap: break-word;
        }

        .entry:hover {
            border-color: #e0e0e0;
        }

        .date {
            font-size: 0.7rem;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            color: var(--accent);
            font-weight: 700;
            margin-bottom: 20px;
            display: block;
        }

        /* --- TYPOGRAPHY & LISTS --- */
        p {
            margin: 0 0 1.2em 0;
        }

        em {
            color: #333;
            font-weight: 500;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: var(--accent);
            text-decoration: none;
            border-bottom: 1px dotted #ccc;
            transition: border-bottom 0.2s, background-color 0.2s;
            
            /* FIX 2: Only force aggressive breaking on URLs/Links */
            word-break: break-all;
        }

        a:hover {
            border-bottom: 1px solid var(--accent);
            background-color: #f0f7ff;
        }

        ul, ol {
            margin: 0 0 1.5em 0;
            padding-left: 20px;
            list-style-type: square;
            color: #444;
        }

        li {
            margin-bottom: 8px;
        }

        /* --- CODE STYLING --- */
        code {
            font-family: "SF Mono", "Fira Code", "Consolas", "Monaco", monospace;
            font-size: 0.88em;
            background: var(--code-bg);
            padding: 2px 6px;
            border-radius: 3px;
            border: 1px solid var(--border);
            color: #c7254e;
            white-space: pre-wrap; /* Allows code to wrap on small screens */
            word-break: normal; /* Do not break code mid-word weirdly */
        }

        /* --- MATHJAX FIX --- */
        
        /* 1. Reset text wrapping for MathJax to prevent vertical stacking */
        mjx-container, .MathJax {
            white-space: nowrap !important;
            word-break: normal !important;
            overflow-wrap: normal !important;
            direction: ltr;
        }

        /* 2. Specific rule for Block Math (Display Mode) to allow scrolling */
        mjx-container[display="true"] {
            display: block !important;
            overflow-x: auto; /* Adds scrollbar if too wide */
            overflow-y: hidden;
            max-width: 100%;
            padding-bottom: 5px;
        }

        /* --- HORIZONTAL RULE --- */
        hr {
            margin: 30px 0;
            border: 0;
            border-top: 1px solid var(--border);
        }

        /* --- UNIFIED RESOURCE GRID (Used for Tools & Databases) --- */
        .resource-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));
            gap: 30px;
            margin-top: 25px;
            margin-bottom: 20px;
        }

        .resource-cat {
            break-inside: avoid;
        }

        .resource-cat > strong {
            display: block;
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            color: var(--meta);
            border-bottom: 1px solid var(--border);
            padding-bottom: 5px;
            margin-bottom: 12px;
        }

        .resource-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .resource-list li {
            font-size: 0.9rem;
            margin-bottom: 6px;
            line-height: 1.4;
            display: flex;
            flex-direction: column;
        }

        .resource-list li .meta {
            font-size: 0.8rem;
            color: #777;
            font-style: italic;
        }

        /* --- COMPACT GRID (Algorithmic Paradigms) --- */
        .compact-grid {
            display: grid;
            /* Adjusted minmax for better mobile fit */
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 25px;
            margin-top: 20px;
            margin-bottom: 20px;
        }

        .grid-cat {
            break-inside: avoid;
        }

        .grid-cat > strong {
            display: block;
            font-size: 0.8rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            color: var(--meta);
            border-bottom: 1px solid var(--border);
            padding-bottom: 5px;
            margin-bottom: 12px;
        }

        .grid-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .grid-list li {
            font-size: 0.9rem;
            margin-bottom: 12px;
            line-height: 1.5;
            padding-left: 0;
        }

        .grid-list li strong {
            color: #333;
        }

        /* --- PROOF BLOCK --- */
        .proof {
            background: #fafbfc;
            border-left: 3px solid var(--accent);
            padding: 20px 25px;
            margin: 20px 0;
            border-radius: 0 4px 4px 0;
            /* Safety scroll for proofs */
            overflow-x: auto; 
        }

        .proof p {
            margin: 0 0 1em 0;
        }

        .proof p:last-child {
            margin-bottom: 0;
        }

        /* --- ALGORITHM DESCRIPTION --- */
        .algorithm-description {
            margin-top: 25px;
        }

        .algorithm-description h3 {
            font-size: 1.1rem;
            margin-top: 0;
            margin-bottom: 1em;
            color: #333;
        }

        .algorithm-description h4 {
            font-size: 0.95rem;
            margin-top: 1.5em;
            margin-bottom: 0.6em;
            color: #444;
        }

        .algorithm-description ol {
            list-style-type: decimal;
        }

        .algorithm-description ol li {
            margin-bottom: 10px;
        }

        /* --- VISUALIZATIONS & MEDIA --- */
        .visualization {
            margin: 30px 0;
            background: #fafafa;
            padding: 15px;
            border-radius: 6px;
            border: 1px solid var(--border);
            text-align: center;
            /* Handle broad content */
            overflow-x: auto;
            max-width: 100%;
        }

        .visualization img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }

        .caption {
            margin-top: 12px;
            font-size: 0.85rem;
            color: var(--meta);
            line-height: 1.5;
            font-style: italic;
            text-align: left;
            padding: 0 10px;
        }

        .notebook-badge {
            margin-top: 20px;
            display: inline-block;
        }

        .notebook-badge img {
            height: 20px;
            border: none;
        }

        .notebook-badge a {
            border-bottom: none;
            /* Badges should not break */
            word-break: normal; 
        }

        .notebook-badge a:hover {
            background-color: transparent;
        }

        /* --- REFERENCES SECTION --- */
        .refs {
            font-size: 0.85rem;
            color: #555;
            border-top: 1px solid var(--border);
            padding-top: 20px;
            line-height: 1.8;
            margin-top: 25px;
        }

        .refs h4 {
            margin-top: 0;
            margin-bottom: 12px;
            font-size: 0.9rem;
            color: #444;
        }

        .refs ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .refs ul li {
            margin-bottom: 10px;
            padding-left: 0;
        }

        .refs a {
            border-bottom: none;
            color: var(--accent);
            font-weight: 500;
        }

        .refs a:hover {
            text-decoration: underline;
            background-color: transparent;
        }

        /* Refs inline style */
        .refs-inline {
            font-size: 0.85rem;
            color: #555;
            border-top: 1px solid var(--border);
            padding-top: 20px;
            line-height: 1.9;
            margin-top: 25px;
        }

        .refs-inline strong {
            display: block;
            margin-bottom: 10px;
            font-size: 0.9rem;
            color: #444;
        }

        .refs-inline a {
            border-bottom: none;
            color: var(--accent);
            font-weight: 500;
        }

        .refs-inline a:hover {
            text-decoration: underline;
            background-color: transparent;
        }

        /* --- MOBILE OPTIMIZATION --- */
        @media (max-width: 600px) {
            header {
                padding: 30px 15px 20px 15px;
            }

            .diary-container {
                padding: 0 10px 100px 10px; /* Reduced side padding */
            }

            .entry {
                padding: 25px 15px; /* Reduced internal padding */
            }

            h1 {
                font-size: 1.5rem;
            }

            /* Force 1 column on mobile to prevent squishing */
            .resource-grid,
            .compact-grid {
                grid-template-columns: 1fr;
                gap: 25px;
            }

            .proof {
                padding: 15px 15px;
            }
            
            /* Smaller font for code on mobile */
            code {
                font-size: 0.8em;
            }
        }
    </style>
</head>
<body>


    <div class="diary-container">

        <div class="entry" id="feb10">
    <div class="date">February 7, 2026</div>
    <h2>Rethinking R&D: The Bell Labs Architecture</h2>

    <p>
        Based on <a href="https://www.sciencedirect.com/science/article/pii/S0048733324000325">"How technoscientific knowledge advances: A Bell-Labs-inspired architecture"</a> by Venkatesh Narayanamurti and Jeffrey Y. Tsao.
    </p>

    <p>
        We often imagine innovation as a pipeline: basic science creates a discovery, applied research refines it, and development turns it into a product. This "Linear Model" is deeply embedded in how we fund and manage science. But according to Venkatesh Narayanamurti (former Dean of Harvard SEAS) and Jeffrey Tsao (Sandia National Labs), this model is fundamentally flawed—and it’s stifling modern discovery.
    </p>

    <p>
        In their paper, they propose a different architecture for knowledge advancement, modeled after the 20th century’s most successful innovation engine: <strong>Bell Labs</strong>.
    </p>

    <h3>The Architecture: Bell’s "Dodecants"</h3>
    <p>
        Narayanamurti and Tsao argue that we must abandon the "Science vs. Technology" dichotomy. Instead, they model innovation as a 12-part grid—the <strong>Dodecants</strong>—formed by crossing <strong>Six Mechanisms</strong> of action with <strong>Two Flavors</strong> of intent.
    </p>

    <h4>The Six Mechanisms (The "Verbs")</h4>
    <p>
        The authors break down the "Scientific Method" ($\dot{S}$) and "Engineering Method" ($\dot{T}$) into three distinct steps each. These are the engines of the process:
    </p>
    <ul>
        <li><strong>$\dot{S}_1$: Fact-Finding.</strong> The accumulation of new data and observations (e.g., measuring the spectral lines of hydrogen).</li>
        <li><strong>$\dot{S}_2$: Explanation-Finding.</strong> Creating models or theories to make sense of facts (e.g., Bohr’s model of the atom).</li>
        <li><strong>$\dot{S}_3$: Generalizing.</strong> Extending theories to cover broader classes of phenomena (e.g., Quantum Mechanics).</li>
        <li><strong>$\dot{T}_1$: Function-Finding.</strong> Identifying a specific utility or need (e.g., "we need to amplify this weak signal").</li>
        <li><strong>$\dot{T}_2$: Form-Finding.</strong> Designing the physical structure to achieve that function (e.g., the geometry of a transistor).</li>
        <li><strong>$\dot{T}_3$: Exapting.</strong> Radical repurposing—using a technology for a completely unintended use (e.g., using a microwave radar magnetron to cook food).</li>
    </ul>

    <h4>The Two Flavors (The "Adverbs")</h4>
    <p>
        Crucially, <em>any</em> of the six mechanisms above can be performed with two different mindsets:
    </p>
    <ul>
        <li><strong>Research Mode (R):</strong> Seeking <em>Surprise</em>. This is divergent thinking, aiming to disrupt current understanding or capability.</li>
        <li><strong>Development Mode (D):</strong> Seeking <em>Consolidation</em>. This is convergent thinking, aiming to refine, stabilize, and make robust.</li>
    </ul>
    <p>
        This creates the 12 "Dodecants." You can do "Explanation-Finding in Development Mode" (refining a known theory) or "Form-Finding in Research Mode" (trying a crazy new transistor design just to see if it switches).
    </p>

    <h3>The Problem: Broken Cycles</h3>
    <p>
        The magic of Bell Labs wasn't just having smart people; it was the fluid movement between these sectors. A physicist stuck on <em>Explanation-Finding</em> ($\dot{S}_2$) could walk down the hall to an engineer doing <em>Form-Finding</em> ($\dot{T}_2$) and realize that a manufacturing anomaly was actually a new quantum effect.
    </p>
    <p>
        Modern R&D often breaks these cycles. "Science" grants fund only the $\dot{S}$ mechanisms, while corporate R&D funds only the $\dot{T}$ mechanisms (and usually only in "Development" mode). The <strong>Exapting</strong> ($\dot{T}_3$) mechanism—often the source of the biggest breakthroughs—is particularly starved because it fits neither pure theory nor immediate product roadmaps.
    </p>

    <h3>Conclusion</h3>
    <p>
        The decline in disruptive breakthroughs isn't due to a lack of ideas, but a rigid architecture that prevents the "Dodecants" from feeding each other. To revive the spirit of Bell Labs, we don't need more money poured into the same silos; we need to nurture the full cyclic flow between surprise and consolidation, facts and functions.
    </p>
</div>

<div class="entry">
    <div class="date">February 7, 2026</div>
    <h2>Taming Mathematical Complexity: How Software Engineering is Reshaping Pure Mathematics</h2>

    <p>
        Based on <a href="https://arxiv.org/pdf/2309.14870">"Abstraction Boundaries and Spec Driven Development in Pure Mathematics"</a> by Johan Commelin and Adam Topaz.
    </p>

    <p>
        Modern mathematics has a scaling problem. New results are becoming increasingly intricate, often relying on deep mastery of multiple disparate subfields. Significant papers now routinely exceed one hundred pages, and the peer review process can drag on for years.
    </p>

    <p>
        In a recent paper, Johan Commelin and Adam Topaz argue that the traditional methods of managing this complexity are hitting their limits. Their solution? Applying principles from software engineering—specifically <strong>Abstraction Boundaries</strong> and <strong>Spec Driven Development</strong>—within the rigid environment of Interactive Theorem Provers (ITPs) like Lean.
    </p>

    <p>
        Here is how these concepts helped a distributed team of mathematicians resolve one of the most difficult challenges in modern arithmetic geometry: The Liquid Tensor Experiment.
    </p>

    <h3>The Problem: Inherent vs. Accidental Complexity</h3>
    <p>
        The authors distinguish between two types of difficulty in mathematics:
    </p>
    <ul>
        <li><strong>Inherent Complexity:</strong> The raw difficulty of the ideas and the breadth of prerequisites required to understand a proof.</li>
        <li><strong>Accidental Complexity:</strong> The friction caused by imperfections in communication—unwritten assumptions, ambiguous definitions, or the mental tax of tracking trivial side conditions (like ensuring a number remains positive throughout a proof).</li>
    </ul>
    <p>
        While mathematicians have long used "abstraction" to simplify problems, the authors argue that doing this on paper often leaves room for accidental complexity to creep back in.
    </p>

    <h3>The Solution: Spec Driven Development (SDD)</h3>
    <p>
        Commelin and Topaz advocate for Spec Driven Development, a workflow where the "specification" (the external behavior of a mathematical object) is separated from its "implementation" (how it is constructed).
    </p>
    <p>
        In a computerized proof assistant like Lean, this allows for a radical change in workflow: <strong>Mathematical Debt</strong>.
    </p>
    <p>
        Using the keyword <code>sorry</code>, a user can create a placeholder for a proof or definition that doesn't exist yet. This allows researchers to write high-level proofs using objects that haven't been built. For example, a mathematician can prove a theorem about an "Abelian Category" by simply asserting that the category exists (tagged with <code>sorry</code>), allowing them to make progress on the main theorem without getting bogged down in the construction details immediately.
    </p>
    <p>
        This recursive process involves:
    </p>
    <ul>
        <li>Isolating a target (definition or theorem).</li>
        <li>Writing a "Spec" (interface) for it.</li>
        <li>Breaking it down into smaller, lower-complexity parts.</li>
        <li>Repeating the process.</li>
    </ul>

    <h3>The Case Study: The Liquid Tensor Experiment (LTE)</h3>
    <p>
        The paper uses the Liquid Tensor Experiment as its primary example. Initiated by Fields Medalist Peter Scholze, the goal was to verify the main theorem of "Liquid Vector Spaces"—a result Scholze described as his most important to date, but one so complex he could no longer hold the entire argument in his head.
    </p>
    <p>
        By using Spec Driven Development, the team could distribute the work among a dozen contributors. An expert in homological algebra could work on the Ext groups, while another contributor worked on the specific properties of p-Banach spaces, connected only by the rigorous "handshake" of the abstraction boundaries.
    </p>
    <p>
        Crucially, this method allowed for refactoring. Just as in software, if a definition needed to be changed (e.g., how Ext groups were implemented), the ITP ensured that the change only affected local files, while the high-level logic remained valid as long as the external "spec" was satisfied.
    </p>

    <h3>The "Duck Test": Trusting the Code</h3>
    <p>
        A common critique of formalized math is the "Alignment Problem": How do we know the code actually represents the math we care about? What if the definition of a "manifold" in the computer is slightly wrong?
    </p>
    <p>
        The authors propose using Abductive Reasoning (inference to the best explanation). They created a test suite of examples to verify their definitions. If the formalized object behaves like the mathematical object in all standard cases—if it looks like a duck and quacks like a duck—we can trust it is a duck.
    </p>

    <h3>Conclusion</h3>
    <p>
        Commelin and Topaz argue that while ITPs have a steep learning curve, they offer a way to "tame" the explosion of complexity in modern research. By enforcing strict abstraction boundaries, computers don't just check proofs; they allow mathematicians to collaborate at a scale that was previously impossible, turning the solitary act of proof-writing into a distributed, architectural engineering feat.
    </p>
</div>

        <!-- Entry: Feb 1 -->
<div class="entry">
    <div class="date">February 1, 2026</div>
    <h2>Notes on the structure of Mathlib: Part I</h2>

    <p>
        I analyze the structure of Mathlib—the mathematical library for Lean 4—as a network. By constructing a co-occurrence graph from 118,517 theorem proofs, I find that formalized mathematics is shallow (81% of premises lie within two hops of reflexivity), naturally modular (493 communities emerge that correspond to mathematical subfields), and contains structural anomalies (premises that are well-connected but underused). The predictive model I trained is largely tautological—degree alone accounts for 89% of its accuracy—but the anomalies it surfaces merit investigation.
    </p>

    <h3>The Question</h3>
    <p>
        Mathlib contains over 150,000 formalized theorems. How is this knowledge organized? What does the dependency structure reveal about mathematics itself?
    </p>
    <p>
        I constructed a graph where nodes are premises (lemmas, definitions, theorems) and edges connect premises that co-occur in proofs. The data comes from LeanDojo Benchmark 4, which traces 118,517 theorem proofs. After filtering edges that appear fewer than 3 times, the graph contains 11,789 nodes and 82,567 edges.
    </p>

    <h3>Finding 1: Mathematics is Shallow</h3>
    <p>
        I computed the shortest-path distance from each premise to a set of "core" nodes: <code>rfl</code>, <code>symm</code>, <code>trans</code>, <code>mul_comm</code>, and <code>mul_assoc</code>. The distribution is striking:
    </p>

    <div class="visualization">
        <table style="width: 100%; border-collapse: collapse; font-size: 0.9rem; text-align: left;">
            <thead>
                <tr>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Depth</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Count</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Cumulative</th>
                </tr>
            </thead>
            <tbody>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;">0</td><td style="padding: 6px; border-bottom: 1px solid #eee;">10</td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.1%</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;">1</td><td style="padding: 6px; border-bottom: 1px solid #eee;">3,276</td><td style="padding: 6px; border-bottom: 1px solid #eee;">27.9%</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;">2</td><td style="padding: 6px; border-bottom: 1px solid #eee;">6,247</td><td style="padding: 6px; border-bottom: 1px solid #eee;">80.9%</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;">3</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,057</td><td style="padding: 6px; border-bottom: 1px solid #eee;">89.9%</td></tr>
                <tr><td style="padding: 6px;">4–7</td><td style="padding: 6px;">149</td><td style="padding: 6px;">100%</td></tr>
            </tbody>
        </table>
    </div>

    <p>
        Over 80% of premises lie within two hops of foundational axioms. The maximum depth is 7. Formalized mathematics, at the proof level, is shallow.
    </p>
    <p>
        This does not contradict the intuition that advanced mathematics builds on long chains of abstraction. A theorem may logically depend on many prior results, yet its proof may "reach back" to <code>rfl</code> directly. The shallowness is structural, not logical.
    </p>

    <h3>Finding 2: The Core</h3>
    <p>PageRank identifies the most central premises:</p>

    <div class="visualization">
        <table style="width: 100%; border-collapse: collapse; font-size: 0.9rem; text-align: left;">
            <thead>
                <tr>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Premise</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">PageRank</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Degree</th>
                </tr>
            </thead>
            <tbody>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>rfl</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0172</td><td style="padding: 6px; border-bottom: 1px solid #eee;">2,213</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>mul_assoc</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0090</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,287</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>mul_comm</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0088</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,327</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>symm</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0082</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,345</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>mul_one</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0072</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,106</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>one_mul</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0060</td><td style="padding: 6px; border-bottom: 1px solid #eee;">1,001</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>trans</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">0.0053</td><td style="padding: 6px; border-bottom: 1px solid #eee;">939</td></tr>
                <tr><td style="padding: 6px;"><code>le_antisymm</code></td><td style="padding: 6px;">0.0047</td><td style="padding: 6px;">753</td></tr>
            </tbody>
        </table>
    </div>

    <p>
        Reflexivity dominates, with nearly twice the centrality of any other premise. Multiplication lemmas rank higher than addition lemmas, reflecting Mathlib's emphasis on abstract algebra where multiplicative notation is primary.
    </p>

    <h3>Finding 3: Natural Communities</h3>
    <p>
        The Louvain algorithm identifies 493 communities from co-occurrence patterns alone—without any semantic information. These correspond to recognizable mathematical areas:
    </p>
    <ul>
        <li><strong>Community 1 (1,867 nodes):</strong> Polynomials, complex analysis</li>
        <li><strong>Community 2 (1,721 nodes):</strong> Measure theory, integration</li>
        <li><strong>Community 3 (1,698 nodes):</strong> Combinatorics, cardinality</li>
        <li><strong>Community 4 (1,636 nodes):</strong> Limits, functional analysis</li>
    </ul>
    <p>The topology of proofs encodes mathematical subject matter.</p>

    <h3>Finding 4: Short Paths Between Distant Domains</h3>
    <p>How does Topology connect to Number Theory? The shortest path:</p>

    <div class="visualization">
        \[
        \texttt{continuous\_of\_discreteTopology} \to \texttt{rfl} \to \texttt{Nat.mul\_comm}
        \]
    </div>

    <p>
        Three hops, through reflexivity. Even distant mathematical domains connect quickly through foundational axioms.
    </p>

    <h3>The Predictive Model (and Its Limitations)</h3>
    <p>
        I trained an XGBoost classifier to predict whether a premise is "high utility" (top 10% by usage). Features: degree, clustering coefficient, community ID.
    </p>
    <ul>
        <li><strong>AUC-ROC:</strong> 0.9791</li>
        <li><strong>Accuracy:</strong> 0.9614</li>
    </ul>
    <p>This appears impressive until one examines feature importance:</p>
    <ul>
        <li><strong>Degree:</strong> 0.892</li>
        <li><strong>Clustering Coefficient:</strong> 0.060</li>
        <li><strong>Community ID:</strong> 0.049</li>
    </ul>
    <p>
        Degree accounts for 89% of predictive power. Degree alone achieves 97.79% AUC. The relationship is nearly tautological: a premise used in many proofs will co-occur with many other premises, mechanically increasing its degree. The model is essentially predicting usage from a correlate of usage.
    </p>

    <h3>Finding 5: Usage Gap Anomalies</h3>
    <p>
        The model's value lies not in prediction but in identifying anomalies. I computed, for each premise, the difference between its actual usage and the expected usage for premises of similar degree. Large gaps indicate premises that are well-connected but underused:
    </p>

    <div class="visualization">
        <table style="width: 100%; border-collapse: collapse; font-size: 0.9rem; text-align: left;">
            <thead>
                <tr>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Premise</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Degree</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Actual</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Exp.</th>
                    <th style="border-bottom: 2px solid #ddd; padding: 8px;">Gap</th>
                </tr>
            </thead>
            <tbody>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>tsum_le_tsum</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">93</td><td style="padding: 6px; border-bottom: 1px solid #eee;">40</td><td style="padding: 6px; border-bottom: 1px solid #eee;">126</td><td style="padding: 6px; border-bottom: 1px solid #eee;">−86</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>val_zero</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">74</td><td style="padding: 6px; border-bottom: 1px solid #eee;">38</td><td style="padding: 6px; border-bottom: 1px solid #eee;">105</td><td style="padding: 6px; border-bottom: 1px solid #eee;">−67</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>cast_abs</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">72</td><td style="padding: 6px; border-bottom: 1px solid #eee;">40</td><td style="padding: 6px; border-bottom: 1px solid #eee;">107</td><td style="padding: 6px; border-bottom: 1px solid #eee;">−67</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>abs_zero</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">52</td><td style="padding: 6px; border-bottom: 1px solid #eee;">36</td><td style="padding: 6px; border-bottom: 1px solid #eee;">81</td><td style="padding: 6px; border-bottom: 1px solid #eee;">−45</td></tr>
                <tr><td style="padding: 6px; border-bottom: 1px solid #eee;"><code>repr_self</code></td><td style="padding: 6px; border-bottom: 1px solid #eee;">45</td><td style="padding: 6px; border-bottom: 1px solid #eee;">37</td><td style="padding: 6px; border-bottom: 1px solid #eee;">71</td><td style="padding: 6px; border-bottom: 1px solid #eee;">−34</td></tr>
                <tr><td style="padding: 6px;"><code>IsIntegral</code></td><td style="padding: 6px;">45</td><td style="padding: 6px;">41</td><td style="padding: 6px;">71</td><td style="padding: 6px;">−30</td></tr>
            </tbody>
        </table>
    </div>

    <p>
        <code>tsum_le_tsum</code>—the monotonicity of infinite sums—is used 86 fewer times than its connectivity would suggest. It is the largest anomaly in Mathlib.
    </p>
    <p>
        For contrast, <code>HasFDerivAt</code> (the Fréchet derivative) was flagged by the model with 91.9% confidence, but its usage gap is 0. It is used exactly as expected for its degree. Not all model predictions indicate true anomalies.
    </p>

    <h3>Interpretation</h3>
    <p>Why might these premises be underused relative to their connectivity?</p>
    <ul>
        <li><strong>Abstraction penalty:</strong> General lemmas like <code>tsum_le_tsum</code> may be less convenient than specialized versions for finite sums.</li>
        <li><strong>Type coercion friction:</strong> Lemmas like <code>cast_abs</code> and <code>val_zero</code> bridge numeric types; users may avoid explicit casts.</li>
        <li><strong>Discoverability:</strong> These lemmas may be poorly documented or absent from common tactics.</li>
        <li><strong>Legitimate alternatives:</strong> Other lemmas may serve the same purpose more naturally.</li>
    </ul>

    <h3>Conclusions</h3>
    <p>Mathlib, viewed as a network, reveals that:</p>
    <ol>
        <li>Formalized mathematics is shallow—most premises lie within two steps of <code>rfl</code>.</li>
        <li>Community structure emerges naturally from proof patterns.</li>
        <li>Some premises exhibit usage gaps worth investigating.</li>
    </ol>
    <p>
        The predictive model is largely tautological. The structural findings are descriptive, not causal. But the portrait that emerges—of a shallow, modular, <code>rfl</code>-centered mathematical universe—is, I think, worth contemplating.
    </p>

    <div class="refs">
        <h4>References</h4>
        <ul>
            <li>
                K. Yang et al.,
                <a href="https://arxiv.org/abs/2306.15626" target="_blank">"LeanDojo: Theorem Proving with Retrieval-Augmented Language Models,"</a>
                <em>NeurIPS</em>, 2023.
            </li>
            <li>
                The mathlib Community,
                <a href="https://doi.org/10.1145/3372885.3373824" target="_blank">"The Lean mathematical library,"</a>
                <em>CPP</em>, 2020.
            </li>
        </ul>
    </div>
</div>

        <div class="entry">
  <div class="date">January 6, 2026</div>
  <h2>Graph likelihood</h2>

  <p>
    Banerji–Mansour–Severini define the <em>likelihood</em> of a graph \(G\) on \(n\) vertices as the probability that a
    “monkey” constructs \(G\) in exactly \(n\) steps by adding one vertex per step:
    at step \(t\) it picks a degree \(k\in\{0,\dots,t-1\}\) uniformly, then picks \(k\) neighbors uniformly among the existing
    \(t-1\) vertices.
    The likelihood is \(L(G)=\Pr(G_n \simeq G)\).
  </p>

  <div class="visualization">
  \[
  L(G)\;=\;\frac{1}{|\mathrm{Aut}(G)|}\sum_{\phi:[n]\overset{\sim}{\to}V(G)}
  \;\prod_{t=2}^{n}\left(\frac{1}{t}\cdot \binom{t-1}{d_t(\phi)}^{-1}\right),
  \qquad
  d_t(\phi):=\bigl|N_G(\phi(t))\cap\{\phi(1),\dots,\phi(t-1)\}\bigr|.
  \]
  </div>

  <p>
    Two immediate remarks:
    (i) the symmetry \(k\leftrightarrow (t-1-k)\) plus \(\binom{t-1}{k}=\binom{t-1}{t-1-k}\) implies
    \(L(G)=L(\overline{G})\);
    (ii) the formula is a “partition function over arrival orders”: a sum over all labelings \(\phi\),
    with a weight that depends only on the <em>back-degrees</em> \(d_t(\phi)\).
  </p>

  <h3>A natural generalization</h3>

  <p>
    The monkey rule “choose \(k\) uniformly” can be replaced by an arbitrary degree law.
    Fix distributions \(p_t\) on \(\{0,\dots,t-1\}\). At step \(t\), first draw \(K_t\sim p_t\), then choose a \(K_t\)-subset uniformly.
    The same derivation yields
  </p>

  <div class="visualization">
  \[
  L_{p}(G)\;=\;\frac{1}{|\mathrm{Aut}(G)|}\sum_{\phi}
  \prod_{t=2}^{n}\left(\frac{p_t(d_t(\phi))}{\binom{t-1}{d_t(\phi)}}\right).
  \]
  </div>

  <p>
    Complement-invariance now holds <em>iff</em> each \(p_t\) is symmetric: \(p_t(k)=p_t(t-1-k)\).
    A pleasant special case is the binomial choice \(p_t(k)=\binom{t-1}{k}q^k(1-q)^{t-1-k}\),
    which makes every subset \(S\subseteq[t-1]\) appear with probability \(q^{|S|}(1-q)^{t-1-|S|}\).
    In that case the labeled distribution is exactly \(G(n,q)\), and the unlabeled likelihood becomes
    \[
      L_{p}(G)=\frac{n!}{|\mathrm{Aut}(G)|}\,q^{m}(1-q)^{\binom{n}{2}-m},
    \]
    where \(m=|E(G)|\).
  </p>

  
<div class="graph-likelihood-entry">

  <h3>Conjecture 1: Minima</h3>
  <p>
    For all \( n \ge 6 \), the graph with the unique minimum likelihood is the balanced complete bipartite graph \( K_{\lfloor n/2 \rfloor, \lceil n/2 \rceil} \).
  </p>
  <p><strong>Status:</strong> Verified computationally for \( n \le 9 \).</p>
  <blockquote>
    <strong>Intuition:</strong> The likelihood of a graph is inversely proportional to the product of binomial coefficients \( \binom{t}{k} \) chosen at each step. To minimize the probability, the generative process must select the <em>maximum</em> possible binomial coefficient at every single step \( t \). Since \( \binom{t}{k} \) is maximized when \( k \approx t/2 \), the "rarest" graph is one that forces the new vertex to connect to exactly half of the existing vertices at every stage of growth. The balanced bipartite structure naturally enforces this constraint.
  </blockquote>

  <hr>

  <h3>Conjecture 2: Primes?</h3>
  <p>
    Let \( L(G) = p/q \) be the likelihood of a graph \( G \) expressed as an irreducible fraction. If there exists another connected, non-isomorphic, non-complementary graph \( G' \) such that \( L(G) = L(G') \), then the numerator \( p \) is a <strong>prime number</strong> (or a product of large primes not dividing the factorial base of the denominator).
  </p>
  <p><strong>Status:</strong> Verified for all deep collisions up to \( n=8 \).</p>
  <ul>
    <li>\( n=5 \): Numerators <strong>13, 41</strong></li>
    <li>\( n=6 \): Numerator <strong>19</strong></li>
    <li>\( n=7 \): Numerators <strong>107, 1693</strong></li>
    <li>\( n=8 \): Numerator <strong>1,508,659</strong></li>
  </ul>
  <blockquote>
    <strong>Why this seems true:</strong> The likelihood \( L(G) \) is a summation of rational probabilities over all possible construction histories of the graph. For highly symmetric graphs (like \( K_n \)), these sums simplify algebraically into smooth fractions (e.g., \( 1/n! \)).
    <br><br>
    However, a "collision" represents an arithmetic accident where two structurally unrelated complex sums equate to the same value. The denominator \( D \) of these sums is highly composite (built from \( 2, 3, 5, \dots \)). When two different sums of rationals unexpectedly align, their reduced numerator tends to be "random" with respect to the smooth denominator. In number theory, a random integer coprime to a smooth number has a high probability of being prime or having large prime factors.
    <br><br>
    Essentially, a prime numerator indicates that the probability value is <strong>atomic</strong>—it cannot be factored down into simpler structural components. It suggests that these ambiguities are fundamental resonances in the generative arithmetic.
  </blockquote>

  <hr>

  <h3>Conjecture 3: Asymptotics</h3>
  <p>
    As \( n \to \infty \), the set of likelihood values \( \{ L(G) : G \in \mathcal{G}_n \} \) becomes dense in the interval \( [0, 1] \) on a logarithmic scale. Furthermore, the number of "Deep Collisions" (distinct likelihoods shared by unrelated graphs) follows a super-exponential growth sequence \( A(n) \):
  </p>
  <p style="text-align: center; font-family: monospace;">
    $$ 0, 0, 0, 0, 2, 3, 5, 35, 282, \dots $$
  </p>
  <p><strong>Status:</strong> The sequence is new (not in OEIS).</p>
  <blockquote>
    <strong>Intuition:</strong> For small \( n \), the "rational resolution" of the process is high enough to distinguish every graph topology. However, the number of graphs grows as \( 2^{\binom{n}{2}} \), while the common denominator of the system grows much slower (roughly factorials). By the Pigeonhole Principle, as \( n \) increases, the probability space becomes overcrowded. We transition from a regime where every graph has a unique "generative fingerprint" to a regime where distinct structures begin to overlap frequently, creating a "continuum" of complexity.
  </blockquote>

</div>
  

  <h3>References</h3>

  <p class="references">
    C. R. S. Banerji, T. Mansour, S. Severini,
    <a href="https://arxiv.org/abs/1304.3600">A notion of graph likelihood and an infinite monkey theorem</a>, arXiv:1304.3600 (2013; published in <em>J. Phys. A</em>).
    &nbsp;—&nbsp;
    D. Dervovic, A. Mocherla, S. Severini,
    <a href="https://arxiv.org/abs/1802.09844">Constructing graphs with limited resources</a>, arXiv:1802.09844 (2018).
    &nbsp;—&nbsp;
    S. Janson, S. Severini,
    <a href="https://archive.intlpress.com/site/pub/files/_fulltext/journals/joc/2013/0004/0001/JOC-2013-0004-0001-a003.pdf">An example of graph limits of growing sequences of random graphs</a>, <em>Journal of Combinatorics</em> 4(1):67–80 (2013).
  </p>
</div>


        <!-- Entry: Jan 4 -->
        <div class="entry">
            <span class="date">January 4, 2026</span>
            <div class="content">
                <p>
                    I have been reading the survey <a href="https://arxiv.org/pdf/2508.20825" target="_blank">arXiv:2508.20825</a>.
                </p>
                <p>
                    Computer-assisted graph theory has evolved from the controversial "brute force" of the 1976 Four Color Theorem to a rigorous discipline. Modern approaches prioritize correctness through formal verification (e.g., using the <strong>Rocq</strong> proof assistant) and independent algorithm reimplementation.
                </p>

                <p>
                    The fundamental engine of the field is <strong>Exhaustive Generation</strong>—producing every non-isomorphic graph in a specific class (e.g., cubic, planar) up to a certain order. The central challenge is <strong>Isomorphism Rejection</strong>: preventing the generation of structurally identical copies without the memory cost of storing every graph found. The survey highlights sophisticated solutions to this:
                </p>

                <ul>
                    <li><strong>Orderly Generation:</strong> Introduced by Faradžev and Reed, this method generates graphs such that only those with a specific "canonical" labeling are accepted. Because validity is determined by the current graph's structure alone, it requires no historical memory.</li>
                    <li><strong>Canonical Construction Path:</strong> Used by the standard tool <code>nauty</code>, this method assumes graphs are built recursively (e.g., adding edges). To avoid duplicating work via different build orders (a problem known as <em>pseudosimilarity</em>), the algorithm defines a "canonical reduction" (a specific way to remove an element). A graph is accepted only if it was generated via the exact reverse of its canonical reduction.</li>
                </ul>

                <p>
                    The field has moved beyond static lists of graphs to dynamic databases like the <strong>House of Graphs</strong>. Unlike standard repositories, these allow researchers to search using inequalities of invariants (e.g., searching for graphs where chromatic number &gt; clique number). This facilitates the discovery of connections between unrelated problems by identifying common counterexamples.
                </p>

                <h3>Algorithmic Paradigms</h3>
                <div class="compact-grid">
                    <div class="grid-cat">
                        <strong>Exact & Algebraic Methods</strong>
                        <ul class="grid-list">
                            <li><strong>Mixed Integer Linear Programming (MILP):</strong> Used for exact structural problems (e.g., Turán numbers). A key feature is duality: finding a solution to the "dual" problem provides a mathematical certificate of optimality, removing the need to blindly trust the solver's software implementation.</li>
                            <li><strong>Semidefinite Programming (SDP) & Flag Algebras:</strong> Introduced by Razborov, Flag Algebras transform combinatorial problems regarding subgraph densities into algebraic inequalities. These are solved via SDP to provide rigorous asymptotic bounds, such as determining exact Ramsey numbers like $R(K_4^-, K_4^-, K_4^-)=28$.</li>
                        </ul>
                    </div>
                    <div class="grid-cat">
                        <strong>Logic & Machine Learning</strong>
                        <ul class="grid-list">
                            <li><strong>SAT Solvers:</strong> Used for boolean constraints, such as the resolution of Keller's Conjecture (dimension 7). Modern solvers produce "proof logs" (e.g., 224 gigabytes for Keller's conjecture) that formally verify the non-existence of a counterexample.</li>
                            <li><strong>Machine Learning:</strong> Recent approaches utilize Reinforcement Learning and Large Language Models (e.g., <strong>FunSearch</strong>) to generate code that searches for "witnesses" (constructions). This method recently improved lower bounds for the Cap Set Problem by evolving algorithms rather than just data.</li>
                        </ul>
                    </div>
                </div>

                <div class="refs">
                    <h4>References</h4>
                    <ul>
                        <li>
                            J. Brakensiek et al.,
                            <a href="https://doi.org/10.1007/s10817-022-09630-x" target="_blank">"The resolution of Keller's conjecture,"</a>
                            <em>Journal of Automated Reasoning</em>, 66(3):277–300, 2022.
                        </li>
                        <li>
                            G. Brinkmann, K. Coolsaet, J. Goedgebeur, and H. Mélot,
                            <a href="https://houseofgraphs.org" target="_blank">"House of Graphs: a database of interesting graphs,"</a>
                            <em>Discrete Applied Mathematics</em>, 161(1-2):311–314, 2013.
                        </li>
                        <li>
                            I. A. Faradžev,
                            "Generation of nonisomorphic graphs with a given degree sequence,"
                            <em>Algorithmic Studies in Combinatorics</em>, pages 11–19, 1978.
                        </li>
                        <li>
                            B. D. McKay,
                            <a href="https://doi.org/10.1006/jagm.1997.0909" target="_blank">"Isomorph-free exhaustive generation,"</a>
                            <em>Journal of Algorithms</em>, 26(2):306–324, 1998.
                        </li>
                        <li>
                            A. A. Razborov,
                            <a href="https://doi.org/10.2178/jsl/1203350781" target="_blank">"Flag algebras,"</a>
                            <em>The Journal of Symbolic Logic</em>, 72(4):1239–1282, 2007.
                        </li>
                        <li>
                            B. Romera-Paredes et al.,
                            <a href="https://www.nature.com/articles/s41586-023-06924-6" target="_blank">"Mathematical discoveries from program search with large language models,"</a>
                            <em>Nature</em>, 625(7995):468–475, 2024.
                        </li>
                        <li>
                            A. Z. Wagner,
                            <a href="https://doi.org/10.1016/j.jcta.2019.105130" target="_blank">"Refuting conjectures in extremal combinatorics via linear programming,"</a>
                            <em>Journal of Combinatorial Theory, Series A</em>, 169:105130, 2020.
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Entry: Jan 3 -->
        <div class="entry">
            <span class="date">January 3, 2026</span>
            <div class="content">
                <h3>Resource-Constrained Graph Construction</h3>
                <p>
                    Fix integers $k,m\ge 0$. We consider a construction process occurring over time steps $t=1,2,\dots,n$.
                    At each time $t$, a new vertex $v_t$ is created. Alice sends an instruction $x_t\in\{0,1\}^k$.
                    Bob maps this instruction to a <em>stored state</em>
                    \[
                    \ell(t) \;=\; \alpha(x_t) \in \Sigma_m, \qquad \text{where } \Sigma_m := \{0,1,\dots,2^m-1\}.
                    \]
                    The state $\ell(t)$ is permanently attached to $v_t$.
                </p>
                <p>
                    The crucial constraint is that the adjacency of $v_t$ to <em>all earlier vertices</em> must be determined solely from the stored states.
                    Concretely, Bob fixes a <em>decoder</em> function once and for all:
                    \[
                    \delta: \Sigma_m \times \Sigma_m \to \{0,1\}.
                    \]
                    Upon creating $v_t$, edges are added according to the rule:
                    \[
                    \{v_i, v_t\} \in E \iff \delta(\ell(i), \ell(t)) = 1 \qquad (\text{for } i < t).
                    \]
                    Intuitively, $\ell(i)$ is the only information Bob can ever access regarding $v_i$ at times $t > i$,
                    and $\ell(t)$ is the only information about $v_t$ that persists beyond time $t$.
                </p>

                <p>
                    <strong>Definition (Resource model $\mathcal{R}(k,m)$).</strong>
                    A graph $G$ is <em>constructible in $\mathcal{R}(k,m)$</em> if there exist functions
                    \[
                    \alpha: \{0,1\}^k \to \Sigma_m, \qquad \delta: \Sigma_m \times \Sigma_m \to \{0,1\},
                    \]
                    and a sequence of instructions $(x_t)_{t=1}^n$ such that, defining $\ell(t) = \alpha(x_t)$,
                    the graph on vertices $v_1,\dots,v_n$ generated by the rule
                    \[
                    \{v_i, v_t\} \in E \iff \delta(\ell(i), \ell(t)) = 1 \quad (i < t)
                    \]
                    is isomorphic to $G$.
                </p>

                <p>
                    <strong>Remark (Indistinguishability).</strong>
                    If $\ell(i) = \ell(j)$ with $i < j$, then for every $t > j$,
                    \[
                    \{v_i, v_t\} \in E \iff \delta(\ell(i), \ell(t)) = 1 \iff \delta(\ell(j), \ell(t)) = 1 \iff \{v_j, v_t\} \in E.
                    \]
                    Thus, vertices sharing a state are indistinguishable to all <em>future</em> vertices.
                    This captures the symmetry enforced by bounded state memory.
                </p>

                <p>
                    To characterize these graphs, we recall the concept of lettericity.
                </p>

                <p>
                    <strong>Definition (Letter graph).</strong>
                    Let $\Sigma$ be a finite alphabet and $D \subseteq \Sigma \times \Sigma$ be a binary relation (the decoder).
                    An ordered graph $G$ with vertices $v_1,\dots,v_n$ is a <em>$(\Sigma,D)$-letter graph</em> if there exists a word $w = w_1 \dots w_n \in \Sigma^n$ such that for all $1 \le i < j \le n$,
                    \[
                    \{v_i, v_j\} \in E(G) \iff (w_i, w_j) \in D.
                    \]
                    The <em>lettericity</em> of an abstract graph $G$, denoted $\text{lett}(G)$, is the minimum $|\Sigma|$ such that $G$ is isomorphic to a $(\Sigma,D)$-letter graph for some $D$.
                </p>

                <p>
                    In our resource model, only the number of <em>distinct</em> states that can effectively appear matters.
                    Alice can send at most $2^k$ distinct instructions, and Bob can store at most $2^m$ distinct states.
                    Thus, the effective alphabet size is bounded by
                    \[
                    K \;:=\; \min\{2^k, 2^m\} \;=\; 2^{\min\{k,m\}}.
                    \]
                </p>

                <p>
                    <strong>Theorem (Operational characterization of lettericity).</strong>
                    A graph $G$ is constructible in $\mathcal{R}(k,m)$ if and only if $\text{lett}(G) \le 2^{\min\{k,m\}}$. Equivalently,
                    \[
                    \mathcal{R}(k,m) \;=\; \{\, G : \text{lett}(G) \le K \,\}.
                    \]
                </p>

                <div class="proof">
                    <p><em>Proof.</em></p>
                    <p>
                        (<em>Forward.</em>) Assume $G$ is produced by a protocol $(\alpha, \delta)$ and instruction sequence $(x_t)_{t=1}^n$. Let
                        \[
                        \Sigma := \{ \ell(t) : 1 \le t \le n \} \subseteq \Sigma_m
                        \]
                        be the set of states that actually occur. Clearly $|\Sigma| \le \min\{2^k, 2^m\} = K$.
                        Define the word $w \in \Sigma^n$ by $w_t := \ell(t)$, and define a decoder relation $D \subseteq \Sigma \times \Sigma$ by $(a,b) \in D \iff \delta(a,b)=1$.
                        By construction, for every $i < j$,
                        \[
                        \{v_i, v_j\} \in E(G) \iff \delta(\ell(i), \ell(j)) = 1 \iff (w_i, w_j) \in D.
                        \]
                        Thus, the constructed graph is a $(\Sigma, D)$-letter graph, implying $\text{lett}(G) \le |\Sigma| \le K$.
                    </p>
                    <p>
                        (<em>Reverse.</em>) Suppose $\text{lett}(G) \le K$. By definition, there exists an ordering of the vertices of $G$,
                        an alphabet $\Sigma$ with $|\Sigma| \le K$, a decoder $D$, and a word $w \in \Sigma^n$ representing the graph.
                        Since $|\Sigma| \le 2^k$, we can injectively encode letters via a map $\text{enc}: \Sigma \hookrightarrow \{0,1\}^k$.
                        Since $|\Sigma| \le 2^m$, we can injectively embed $\Sigma$ into $\Sigma_m$ via $\iota: \Sigma \hookrightarrow \Sigma_m$.
                        Fix an arbitrary $a_0 \in \Sigma$ and define:
                        \[
                        \alpha(x) := \begin{cases} \iota(a) & \text{if } x = \text{enc}(a) \text{ for some } a \in \Sigma, \\ \iota(a_0) & \text{otherwise}. \end{cases}
                        \]
                        Define the decoder $\delta$ such that for any $a,b \in \Sigma$, $\delta(\iota(a), \iota(b)) = 1 \iff (a,b) \in D$, and 0 otherwise.
                        With the instruction sequence $x_t := \text{enc}(w_t)$, we have $\ell(t) = \iota(w_t)$.
                        The edge rule $\{v_i, v_j\} \in E \iff \delta(\ell(i), \ell(j)) = 1$ reproduces exactly the condition $(w_i, w_j) \in D.
                        Thus, $G$ is constructible in $\mathcal{R}(k,m)$.
                        <span style="float:right;">$\square$</span>
                    </p>
                </div>

                <div class="refs">
                    <h4>References</h4>
                    <ul>
                        <li>
                            D. Dervovic, A. Mocherla, and S. Severini,
                            <a href="https://arxiv.org/abs/1802.09844" target="_blank">"Constructing graphs with limited resources,"</a>
                            <em>arXiv:1802.09844</em>, 2018.
                        </li>
                        <li>
                            M. Petkovšek,
                            <a href="https://doi.org/10.1016/S0012-365X(01)00094-2" target="_blank">"Letter graphs and well-quasi-order,"</a>
                            <em>Discrete Mathematics</em>, vol. 244, no. 1–3, pp. 375–388, 2002.
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Entry: Jan 1 -->
        <div class="entry">
            <span class="date">January 1, 2026</span>
            <div class="content">
                <p>A curated collection of databases for mathematical objects:</p>

                <div class="resource-grid">
                    <div class="resource-cat">
                        <strong>Sequences & Numbers</strong>
                        <ul class="resource-list">
                            <li>
                                <a href="https://oeis.org" target="_blank">OEIS</a>
                                <span class="meta">— Integer sequences</span>
                            </li>
                            <li>
                                <a href="https://www.lmfdb.org" target="_blank">LMFDB</a>
                                <span class="meta">— L-functions & modular forms</span>
                            </li>
                        </ul>
                    </div>

                    <div class="resource-cat">
                        <strong>Graphs</strong>
                        <ul class="resource-list">
                            <li><a href="https://houseofgraphs.org" target="_blank">House of Graphs</a></li>
                            <li>
                                <a href="https://discretezoo.xyz" target="_blank">DiscreteZOO</a>
                                <span class="meta">— Maniplexes</span>
                            </li>
                            <li>
                                <a href="https://phoeg.umons.ac.be" target="_blank">PHOEG</a>
                                <span class="meta">— Extremal theory</span>
                            </li>
                            <li><a href="http://atlas.gregas.eu" target="_blank">Encyclopedia of Graphs</a></li>
                            <li>
                                <a href="https://users.cecs.anu.edu.au/~bdm/data/" target="_blank">McKay's Data</a>
                                <span class="meta">— Ramsey/Regular</span>
                            </li>
                        </ul>
                    </div>

                    <div class="resource-cat">
                        <strong>Topology</strong>
                        <ul class="resource-list">
                            <li>
                                <a href="https://topology.pi-base.org/" target="_blank">$\pi$-Base</a>
                                <span class="meta">— Counterexamples</span>
                            </li>
                            <li><a href="http://www.map.mpim-bonn.mpg.de/Main_Page" target="_blank">Manifold Atlas</a></li>
                            <li>
                                <a href="https://knotinfo.math.indiana.edu" target="_blank">KnotInfo</a>
                                <span class="meta">— Invariants</span>
                            </li>
                            <li>
                                <a href="https://regina-normal.github.io" target="_blank">Regina</a>
                                <span class="meta">— 3-manifolds</span>
                            </li>
                        </ul>
                    </div>

                    <div class="resource-cat">
                        <strong>Algebra & Geometry</strong>
                        <ul class="resource-list">
                            <li>
                                <a href="https://people.maths.bris.ac.uk/~matyd/GroupNames/" target="_blank">GroupNames</a>
                                <span class="meta">— Finite groups</span>
                            </li>
                            <li>
                                <a href="http://brauer.maths.qmul.ac.uk/Atlas/v3/" target="_blank">ATLAS</a>
                                <span class="meta">— Representations</span>
                            </li>
                            <li>
                                <a href="http://grdb.co.uk" target="_blank">GRDB</a>
                                <span class="meta">— Rings</span>
                            </li>
                            <li>
                                <a href="http://hep.itp.tuwien.ac.at/~kreuzer/CY/" target="_blank">PALP</a>
                                <span class="meta">— Calabi-Yau</span>
                            </li>
                        </ul>
                    </div>

                    <div class="resource-cat">
                        <strong>Combinatorics</strong>
                        <ul class="resource-list">
                            <li>
                                <a href="https://ljcr.dmgordon.org" target="_blank">La Jolla</a>
                                <span class="meta">— Covering designs</span>
                            </li>
                            <li>
                                <a href="http://www.math.rwth-aachen.de/~Gabriele.Nebe/LATTICES/" target="_blank">Lattices</a>
                                <span class="meta">— Nebe-Sloane</span>
                            </li>
                            <li>
                                <a href="https://www.findstat.org" target="_blank">FindStat</a>
                                <span class="meta">— Statistics</span>
                            </li>
                            <li><a href="https://www-imai.is.s.u-tokyo.ac.jp/~yMDitroid/" target="_blank">Matroid Atlas</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Entry: Dec 31 -->
        <div class="entry">
            <span class="date">December 31, 2025</span>
            <div class="content">
                <p>
                    A <em>Moore graph</em> of diameter $2$ and degree $k$ is a regular graph with the theoretical maximum number of vertices allowed by the degree-diameter bound.
                    Counting neighbors layer by layer, we have $1$ root, $k$ neighbors, and $k(k-1)$ vertices at distance 2. Thus, the total number of vertices is
                    $$n = 1 + k + k(k-1) = k^2 + 1.$$
                </p>

                <p>
                    Hoffman and Singleton (1960) proved a stunning spectral constraint: for such a graph to exist, $k$ must belong to the set $\{2, 3, 7, 57\}$.
                    The first three are known:
                </p>

                <ul>
                    <li>$k=2$: The pentagon ($5$ vertices).</li>
                    <li>$k=3$: The Petersen graph ($10$ vertices).</li>
                    <li>$k=7$: The Hoffman-Singleton graph ($50$ vertices).</li>
                </ul>

                <p>
                    The case $k=57$ requires a graph with $57^2+1 = 3250$ vertices. Its existence has been an open problem for over 60 years.
                    In <a href="https://doi.org/10.1016/j.ejco.2023.100060" target="_blank"><em>The missing Moore graph as an optimization problem</em></a> (2023), Smith and Montemanni attack this construction not via algebra, but as a massive optimization task.
                </p>

                <p>
                    They attempt to minimize the <em>deficit</em>—the number of missing edges required to satisfy the Moore constraints.
                    Despite running parallelized hill-climbing algorithms for 18 months, they converged to a solution with a deficit of $41{,}482$ edges (missing nearly half the required edges).
                    While they suggest this points to non-existence, the rugged landscape of high-girth graphs makes it a fascinating testbed for evolutionary algorithms.
                </p>
            </div>
        </div>

        <!-- Entry: Dec 26 -->
        <div class="entry">
            <span class="date">December 26, 2025</span>
            <div class="content">
                <p>
                    A <em>Markov triple</em> is a triple of positive integers $(x,y,z)$ satisfying
                    $$x^2+y^2+z^2 = 3xyz.$$
                    The integers that occur in Markov triples are the <em>Markov numbers</em>.
                    The usual way to navigate the set of solutions is the Vieta move: if $(x,y,z)$ is a solution, then so is
                    $$(x,y,3xy-z),$$
                    and similarly by cycling coordinates. Iterating these involutions (and permuting) generates the Markov tree.
                </p>

                <p>
                    Fibonacci numbers are slower creatures: $F_0=0$, $F_1=1$, and $F_{n+1}=F_n+F_{n-1}$.
                </p>

                <p>
                    The question is <em>which Markov triples have a Fibonacci number as their largest entry?</em>
                    There is one branch where Fibonacci numbers show up for free and this is the branch of triples that contain a $1$.
                </p>

                <p>
                    If $x=1$, the Markov equation becomes
                    $$y^2+z^2+1 = 3yz.$$
                    Solving for $z$ gives
                    $$z=\frac{3y\pm\sqrt{5y^2-4}}{2},$$
                    so integrality forces $5y^2-4$ to be a square. The resulting positive solutions are exactly
                    $$(1, F_{2n-1}, F_{2n+1}) \qquad (n\ge 1),$$
                    e.g.
                </p>

                <ul>
                    <li>$(1,F_1,F_3)=(1,1,2)$</li>
                    <li>$(1,F_3,F_5)=(1,2,5)$</li>
                    <li>$(1,F_5,F_7)=(1,5,13)$</li>
                </ul>

                <p>
                    I added a Colab notebook on GitHub that draws the tree with this spine highlighted. Off the spine, the Vieta update is typically multiplicative ($z'\approx 3xy$ once both $x$ and $y$ grow).
                </p>

                <div class="visualization">
                    <img
                        src="https://raw.githubusercontent.com/simoneseverini/automated-discovery-site/main/Fibonacci_Markov_spine_3.png"
                        alt="Markov tree layout showing the Fibonacci spine highlighted in red and side branches in blue"
                        loading="lazy"
                    />
                    <div class="caption">
                        The Fibonacci spine (red) and the side branches (blue). Once you leave the spine, the magnitudes accelerate so fast that hitting a Fibonacci value starts to feel like a category error. For background on tree layouts, see the <a href="https://cs.brown.edu/people/rtamassi/gdhandbook/chapters/trees.pdf" target="_blank">Trees chapter</a> of the Graph Drawing Handbook.
                    </div>
                </div>

                <div class="notebook-badge">
                    <a href="https://github.com/simoneseverini/automated-discovery-site/blob/main/Markov_Fibonacci_drawing_Dec_26.ipynb" target="_blank">
                        <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
                    </a>
                </div>
            </div>
        </div>

        <!-- Entry: Dec 24 -->
        <div class="entry">
            <span class="date">December 24, 2025</span>
            <div class="content">
                <p>
                    These slides by Michel Waldschmidt are an introduction to <a href="https://webusers.imj-prg.fr/~michel.waldschmidt/articles/pdf/Markoff-en.pdf" target="_blank">Markoff Numbers</a>.
                </p>

                <div class="refs">
                    <h4>Selected References</h4>
                    <ul>
                        <li><a href="https://www.cambridge.org/core/journals/canadian-mathematical-bulletin/article/on-the-unicity-conjecture-for-markoff-numbers/88B0E426FFCBEA8B3A345C1074B8CC59" target="_blank">Baragar (1996), On the Unicity Conjecture</a></li>
                        <li><a href="https://ora.ox.ac.uk/objects/uuid%3Afc6f3446-4389-41e2-9cb4-d75505137821/files/m79f46f4a2e7ff1cbec2f7e7d8b22e737" target="_blank">Button (2001), Markoff Numbers & Continued Fractions</a></li>
                        <li><a href="https://www.sciencedirect.com/science/article/pii/S0022314X13000401" target="_blank">Chen (2013), On the Frobenius Conjecture</a></li>
                        <li><a href="https://arxiv.org/pdf/math/0612620.pdf" target="_blank">Zhang (2006), Proof of uniqueness for prime-power</a></li>
                        <li><a href="https://www.heldermann-verlag.de/jlt/jlt18/torla2e.pdf" target="_blank">Tornero (2008), A Geometric Approach</a></li>
                        <li><a href="https://arxiv.org/abs/2010.10335" target="_blank">Lagisquet (2020), Markov tree / Stern–Brocot indexing</a></li>
                        <li><a href="https://arxiv.org/pdf/2010.13010.pdf" target="_blank">Lee (2022), On the ordering of the Markov numbers</a></li>
                        <li><a href="https://bhbowditch.com/papers/bhb-markoff.pdf" target="_blank">Bowditch, Markoff triples and quasifuchsian groups</a></li>
                        <li><a href="https://www-users.cse.umn.edu/~musiker/Markoff2003.pdf" target="_blank">Itsara et al. (2003), Combinatorial Interpretations</a></li>
                        <li><a href="https://escholarship.org/uc/item/6pn049mp" target="_blank">Labbé (2022), The q-analog over words</a></li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Entry: Dec 23 -->
        <div class="entry">
            <span class="date">December 23, 2025</span>
            <div class="content">
                <p>
                    I have been looking at the <a href="https://web.math.princeton.edu/~pds/barbados25/problems.pdf" target="_blank">Open Problems for the 2025 Barbados Graph Theory Workshop</a>.
                    This collection, compiled by Julien Codsi, features a number of intriguing problems.
                </p>
            </div>
        </div>

       <!-- Entry: Dec 19 -->
<div class="entry">
    <span class="date">December 19, 2025</span>
    <div class="content">
        <h2>Correction Width</h2>

        <h3>Definition (Correction width with $k$ labels)</h3>
        <p>
            Let $G=(V,E)$ be a graph and let $k\ge 1$.
            The <em>correction width</em> of $G$ with $k$ labels, denoted $\text{cw}_k(G)$,
            is the minimum integer $d$ such that there exist:
        </p>
        <ul>
            <li>a linear ordering $\pi=(v_1,\dots,v_n)$ of $V$, and</li>
            <li>a partition of $V$ into $k$ (possibly empty) classes
                \[ V = V_1 \,\dot{\cup}\, V_2 \,\dot{\cup}\, \cdots \,\dot{\cup}\, V_k, \]
            </li>
        </ul>
        <p>
            satisfying the following local approximation property:
        </p>
        <p>
            For each time step $t\in\{1,\dots,n\}$ let $V_{\lt t}:=\{v_1,\dots,v_{t-1}\}$
            and let $N_{\lt t}(v_t):=N(v_t)\cap V_{\lt t}$ be the set of predecessors adjacent to $v_t$.
            There must exist a <em>template set</em> $T_t$ of the form
            \[
              T_t \;=\; \bigcup_{i\in S_t}\bigl(V_{\lt t}\cap V_i\bigr)
              \qquad\text{for some subset } S_t\subseteq [k]:=\{1,\dots,k\},
            \]
            such that
            \[
              \bigl|\,N_{\lt t}(v_t)\,\Delta\,T_t\,\bigr| \;\le\; d.
            \]
        </p>

        <p>
            <strong>Remark.</strong> For $k=2$ this yields exactly four possible templates
            $\emptyset$, $V_{\lt t}$, $V_{\lt t}\cap V_1$, $V_{\lt t}\cap V_2$,
            matching the "connect to none / all / group 1 / group 2" intuition.
        </p>

        <h3>Definition (Permutation-mutable error construction)</h3>
        <p>
            Fix integers $k\ge 1$ and $d\ge 0$.
            A graph $G=(V,E)$ belongs to $\mathcal{G}^{\mathrm{perm}}_{\mathrm{error}}(k,d)$
            if there exists a sequential construction of $G$ that proceeds in steps
            $t=1,\dots,n$ adding vertices in some order $(v_1,\dots,v_n)$, together with:
        </p>
        <ul>
            <li>a label assignment $\ell_t(v_s)\in[k]$ for each already created vertex $v_s$,</li>
            <li>at each step $t$, an optional global relabeling by a <em>permutation</em> $\sigma_t\in S_k$ applied to all current labels (i.e., $\ell_{t}(x)=\sigma_t(\ell_{t-1}(x))$),</li>
            <li>a default connection mask $S_t\subseteq[k]$ specifying that, by default, the new vertex $v_t$ connects to every predecessor whose <em>current</em> label lies in $S_t$,</li>
            <li>and an error set $E_t\subseteq V_{\lt t}$ of size at most $d$, whose adjacencies to $v_t$ are <em>toggled</em> relative to the default rule.</li>
        </ul>
        <p>
            Formally, after choosing $\sigma_t$, $S_t$ and $E_t$, the adjacency between $v_t$ and a predecessor $u\in V_{\lt t}$ is set to
            \[
              \mathbf{1}_{\{u v_t\in E\}}
              \;=\;
              \mathbf{1}_{\{\ell_t(u)\in S_t\}} \;\oplus\; \mathbf{1}_{\{u\in E_t\}},
            \]
            where $\oplus$ is XOR. The labels of the new vertex can be assigned arbitrarily in $[k]$.
        </p>

        <h3>Theorem (Equivalence)</h3>
        <p>
            For every graph $G$ and every $k\ge 1$,
            \[
              \text{cw}_k(G)
              \;=\;
              \min\bigl\{\, d\in\mathbb{N} \;:\; G\in \mathcal{G}^{\mathrm{perm}}_{\mathrm{error}}(k,d)\,\bigr\}.
            \]
            In particular, for $k=2$ this identifies $\text{cw}(G):=\text{cw}_2(G)$ with the minimum
            per-step correction budget in the $2$-label permutation-mutable error model.
        </p>

        <div class="proof">
            <p><strong>Proof.</strong></p>
            <p>
                (<em>Forward direction</em>.) Assume $\text{cw}_k(G)\le d$ as witnessed by an ordering
                $\pi=(v_1,\dots,v_n)$ and a partition $V=\dot{\cup}_{i=1}^k V_i$.
                Construct $G$ sequentially in this order.
                Assign each vertex $v_t$ the fixed label $i$ with $v_t\in V_i$ and never relabel
                (i.e., take all $\sigma_t=\mathrm{id}$).
            </p>
            <p>
                At step $t$, let $T_t=\bigcup_{i\in S_t}(V_{\lt t}\cap V_i)$ be a template satisfying
                $|N_{\lt t}(v_t)\Delta T_t|\le d$. Use the default connection mask $S_t$ (connect to all
                predecessors with label in $S_t$), and set the error set to
                $E_t := N_{\lt t}(v_t)\Delta T_t.$
                Then $|E_t|\le d$ and, by construction, the toggling rule realizes exactly the desired
                neighborhood $N_{\lt t}(v_t)$. Hence $G\in \mathcal{G}^{\mathrm{perm}}_{\mathrm{error}}(k,d)$.
            </p>
            <p>
                (<em>Reverse direction</em>.) Assume $G\in \mathcal{G}^{\mathrm{perm}}_{\mathrm{error}}(k,d)$.
                Fix a realizing construction in the order $(v_1,\dots,v_n)$.
                Because each global relabeling is a permutation, labels are only <em>renamed</em> over time.
            </p>
            <p>
                Define the <em>final label</em> of a vertex $x$ to be the label it has after the last step,
                and let $V_i$ be the set of vertices of final label $i$. This yields a partition
                $V=\dot{\cup}_{i=1}^k V_i$.
            </p>
            <p>
                Now consider any step $t$ and any predecessor $u\in V_{\lt t}$.
                Since relabelings are permutations, there exists a bijection $\rho_t:[k]\to[k]$ such that
                the <em>current</em> label class $j$ at time $t$ corresponds exactly to the final class $\rho_t(j)$,
                restricted to predecessors:
                \[
                  \{u\in V_{\lt t}:\ell_t(u)=j\} \;=\; V_{\lt t}\cap V_{\rho_t(j)}.
                \]
                The default rule at step $t$ uses a mask $S_t\subseteq[k]$, hence the default neighborhood is
                \[
                  T_t \;:=\; \{u\in V_{\lt t}:\ell_t(u)\in S_t\}
                  \;=\; \bigcup_{j\in S_t}\bigl(V_{\lt t}\cap V_{\rho_t(j)}\bigr),
                \]
                which is a union of predecessor-pieces of the <em>fixed</em> final partition.
                The construction then toggles adjacency on at most $d$ vertices $E_t$, so
                \[
                  N_{\lt t}(v_t) \;=\; T_t \,\Delta\, E_t
                  \qquad\Longrightarrow\qquad
                  |N_{\lt t}(v_t)\Delta T_t| \;=\; |E_t| \;\le\; d.
                \]
                Thus the same ordering and the final partition witness $\text{cw}_k(G)\le d$.
            </p>
            <p>
                Combining both directions proves the claimed equality. <span style="float:right;">$\square$</span>
            </p>
        </div>

        <p>
            <strong>Remark (If merges are allowed).</strong>
            If the mutable model permits non-bijective relabelings (merges), the reverse direction above
            can fail: merging can temporarily collapse multiple classes and later recreate two labels,
            allowing constructions with smaller $d$ than any <em>fixed</em> partition can support.
            In that setting one should either restrict to permutations (as above) or define a
            <em>dynamic</em> correction width where the partition is allowed to evolve.
        </p>
    </div>
</div>

        <!-- Entry: Dec 17 -->
        <div class="entry">
            <span class="date">December 17, 2025</span>
            <div class="content">
                <p>
                    The <em>Shannon capacity</em> of a graph $G$ is defined as $$\Theta(G) = \lim_{d \to \infty} (\alpha(G^d))^{1/d}.$$ The best lower bound for 7-cycle graph $C_7$ was obtained by finding an independent set of size 367 in the fifth power. This yields: $$\Theta(C_7) \geq \sqrt[5]{367} \approx 3.2578.$$ See <a href="https://arxiv.org/abs/1808.07438" target="_blank">arXiv:1808.07438</a> for details. Below is a Colab notebook generated with AlphaEvolve. It gives the same result.
                </p>

                <div class="notebook-badge">
                    <a href="https://github.com/simoneseverini/automated-discovery-site/blob/main/C_7_Shannon_capacity_lower_bound.ipynb" target="_blank">
                        <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
                    </a>
                </div>

                <div class="algorithm-description">
                    <h3>Algorithm for Lower Bounding the Shannon Capacity of $C_7$</h3>

                    <h4>Problem Definition</h4>
                    <p>
                        The algorithm searches for the Maximum Independent Set (MIS) in the graph $G = C_7^n$, which is the strong product of $n$ copies of the 7-cycle.
                    </p>
                    <ul>
                        <li><strong>Vertex Set:</strong> $V = \mathbb{Z}_7^n = \{0, 1, \dots, 6\}^n$.</li>
                        <li><strong>Adjacency:</strong> Two vertices $u, v \in V$ are adjacent if and only if:
                        $$ \forall i \in \{1, \dots, n\}, \quad (u_i - v_i) \pmod 7 \in \{0, 1, 6\}. $$
                        (Note: $6 \equiv -1 \pmod 7$).</li>
                    </ul>
                    <p>
                        An independent set $S \subseteq V$ requires that for any distinct pair $u, v \in S$, they are non-adjacent. The size of this set establishes a lower bound for the Shannon capacity: $\Theta(C_7) \geq |S|^{1/n}$.
                    </p>

                    <h4>Methodology: Randomized Iterated Local Search</h4>
                    <p>
                        The approach implements a <em>Ruin and Recreate</em> strategy combined with greedy construction and local optimization.
                    </p>
                    <ol>
                        <li><strong>Initialization:</strong> The search is seeded either with a known structured subset (e.g., based on the pattern $\{0, 2, 4\}^n$) or a previous best solution.</li>
                        <li><strong>Greedy Construction:</strong> The algorithm maintains an array of "forbidden counts" for every vertex. It iteratively selects random valid vertices (count = 0) and updates the counts of their neighbors.</li>
                        <li><strong>Local Search (1-Swaps):</strong> Once the set is maximal, the algorithm attempts to escape local optima. It selects a vertex $u \in S$ and checks if it is "critical" (i.e., removing it liberates new vertices blocked <em>only</em> by $u$). If so, $u$ is removed, and the greedy process immediately fills the gap, effectively performing a $(1, k)$-swap optimization.</li>
                        <li><strong>Perturbation (Ruin and Recreate):</strong> If the solution size stagnates, the algorithm randomly removes approximately 10% of the vertices (Ruin) and refills the set using the Greedy Construction (Recreate).</li>
                    </ol>

                    <div class="visualization">
                        <img
                            src="https://raw.githubusercontent.com/simoneseverini/automated-discovery-site/main/C_7_5_independent.png"
                            alt="Independent Set Structure Matrix showing a 5x5 grid of plots visualizing the structure of the Independent Set found in C_7^5"
                            loading="lazy"
                        />
                        <div class="caption">
                            <strong>Structure of the Independent Set ($C_7^5$).</strong> The image is a $5 \times 5$ matrix of plots visualizing the structure of the Independent Set (IS) found in the 5-dimensional space ($C_7^5$). Here's how to read it:
                            <br><br>
                            <strong>Diagonal Plots (Top-Left to Bottom-Right):</strong> These are histograms for each of the 5 dimensions. They show the frequency of each coordinate value (0 through 6). For example, if you see taller bars at 0, 2, and 4, it means those values appear more frequently in that specific dimension, hinting that the solution might be built around a specific pattern like $\{0, 2, 4\}$.
                            <br><br>
                            <strong>Off-Diagonal Plots:</strong> These are 2D heatmaps showing the relationship between pairs of dimensions (e.g., Row 0, Column 1 shows Dimension 0 vs. Dimension 1). The color intensity (purple to yellow) represents the number of points at that specific $(x, y)$ coordinate pair. These projections reveal correlations. For an Independent Set in a strong product graph, you often see specific sparse patterns or "holes" because certain combinations of coordinates are forbidden to maintain the non-adjacency constraint.
                            <br><br>
                            Overall, this visualization helps verify if the solution is a structured product (e.g., looks like a clean grid) or a more random packing.
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>

</body>
</html>
